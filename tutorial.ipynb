{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1306c8f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:03:01.082213Z",
     "start_time": "2025-08-28T10:02:49.597887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "\n",
    "os.environ[\"JULIA_NUM_THREADS\"] = \"8\"\n",
    "from julia import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "\n",
    "from julia import Main\n",
    "print(Main.eval(\"Threads.nthreads()\"))\n",
    "from src.VIV_gym import JuliaEnv\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Lib支持\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback, CallbackList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2fe78b430b301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:03:44.764763Z",
     "start_time": "2025-08-28T10:03:44.757683Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "反馈reward和建立checkpoint\n",
    "\n",
    "\"\"\"\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.current_rewards = None\n",
    "        self.episode_steps = []          # 存每个 episode 的 step 数\n",
    "        self.current_steps = None\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        self.current_rewards = np.zeros(self.training_env.num_envs)\n",
    "        self.current_steps = np.zeros(self.training_env.num_envs, dtype=int)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        rewards = self.locals[\"rewards\"]\n",
    "        dones = self.locals[\"dones\"]\n",
    "        self.current_rewards += rewards\n",
    "        self.current_steps += 1   # 每个 step 累加\n",
    "\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                self.episode_rewards.append(self.current_rewards[i])\n",
    "                self.episode_steps.append(self.current_steps[i])  # 记录步数\n",
    "\n",
    "                print(f\"Episode finished after {self.current_steps[i]} steps\")\n",
    "                print(f\"Episode reward: {self.current_rewards[i]:.2f}\")\n",
    "                # reset\n",
    "                self.current_rewards[i] = 0.0\n",
    "                self.current_steps[i] = 0\n",
    "\n",
    "        return True\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq= 1000,\n",
    "    save_path=\"./checkpoints/\",\n",
    "    name_prefix=\"ppo_model\",\n",
    "    save_replay_buffer=True,\n",
    "    save_vecnormalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7553a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:03:45.729164Z",
     "start_time": "2025-08-28T10:03:45.717647Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "训练用参数(VIV)\n",
    "\n",
    "\"\"\"\n",
    "diameter = 16\n",
    "def pos_generator():\n",
    "    return [0.0, np.random.uniform(- diameter/6, diameter/6)]\n",
    "\n",
    "# static parameters\n",
    "statics = {\n",
    "    \"L_unit\": diameter,\n",
    "    \"action_scale\": 50,\n",
    "    \"size\": [10, 8],\n",
    "    \"location\": [3, 4]\n",
    "}\n",
    "#variable parameters\n",
    "variables = {\n",
    "    \"position\":[0.0, diameter/6],\n",
    "    \"velocity\":[0.0, 0.0]\n",
    "}\n",
    "# size of action sapce and observation spaces\n",
    "spaces = {\n",
    "    \"action\":1,\n",
    "    \"observation\":3\n",
    "}\n",
    "\n",
    "from src.VIV_gym import VIVEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "训练用参数(FOIL)\n",
    "\n",
    "\"\"\"\n",
    "diameter = 16\n",
    "\n",
    "# static parameters\n",
    "statics = {\n",
    "    \"L_unit\": diameter,\n",
    "    \"F_scale\": 10,\n",
    "    \"size\": [8, 6],\n",
    "    \"nose\": [1, 4],\n",
    "    \"rot_center\":[0.25,0]\n",
    "}\n",
    "#variable parameters\n",
    "variables = {\n",
    "    \"position\":[0.0, 0.0],\n",
    "    \"velocity\":[0.0, 0.0],\n",
    "    \"theta\":0.05 * np.pi,\n",
    "    \"rot_vel\": 0.0,\n",
    "    \"rot_acc\": 0.0\n",
    "}\n",
    "# size of action sapce and observation spaces\n",
    "spaces = {\n",
    "    \"action\":1,\n",
    "    \"observation\":5\n",
    "}\n",
    "\n",
    "from src.VIV_gym import FoilEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "训练用参数(Drag)\n",
    "\n",
    "\"\"\"\n",
    "diameter = 48\n",
    "\n",
    "def ksi_generator():\n",
    "    return np.random.uniform(3.0, 4.0)\n",
    "\n",
    "# static parameters\n",
    "statics = {\n",
    "    \"L_unit\": diameter,\n",
    "    \"F_scale\": 8,\n",
    "    \"L_ratio\": 0.15,\n",
    "    \"L_gap\":0.05,\n",
    "    \"location\": [2, 0],\n",
    "    \"size\": [6, 2]\n",
    "}\n",
    "# variable parameters\n",
    "variables = {\n",
    "    \"ksi\": ksi_generator\n",
    "}\n",
    "# size of action sapce and observation spaces\n",
    "spaces = {\n",
    "    \"action\":1,\n",
    "    \"observation\":2\n",
    "}\n",
    "\n",
    "from src.VIV_gym import DragEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defbdcbcd7d8e0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:06:25.845138Z",
     "start_time": "2025-08-28T10:03:47.256889Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<PyCall.jlwrap (in a Julia function called from Python)\nJULIA: SystemError: opening file \"e:\\\\New_Env\\\\src\\\\VIV_Env_3.jl\": No such file or directory\nStacktrace:\n  [1] systemerror(p::String, errno::Int32; extrainfo::Nothing)\n    @ Base .\\error.jl:176\n  [2] systemerror\n    @ .\\error.jl:175 [inlined]\n  [3] open(fname::String; lock::Bool, read::Nothing, write::Nothing, create::Nothing, truncate::Nothing, append::Nothing)\n    @ Base .\\iostream.jl:293\n  [4] open\n    @ .\\iostream.jl:275 [inlined]\n  [5] open(f::Base.var\"#433#434\"{String}, args::String; kwargs::@Kwargs{})\n    @ Base .\\io.jl:394\n  [6] open\n    @ .\\io.jl:393 [inlined]\n  [7] read\n    @ .\\io.jl:486 [inlined]\n  [8] _include(mapexpr::Function, mod::Module, _path::String)\n    @ Base .\\loading.jl:2202\n  [9] include(fname::String)\n    @ Base.MainInclude .\\client.jl:494\n [10] invokelatest(::Any, ::Any, ::Vararg{Any}; kwargs::@Kwargs{})\n    @ Base .\\essentials.jl:892\n [11] invokelatest(::Any, ::Any, ::Vararg{Any})\n    @ Base .\\essentials.jl:889\n [12] _pyjlwrap_call(f::Function, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n    @ PyCall C:\\Users\\admin\\.julia\\packages\\PyCall\\1gn3u\\src\\callback.jl:28\n [13] pyjlwrap_call(self_::Ptr{PyCall.PyObject_struct}, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n    @ PyCall C:\\Users\\admin\\.julia\\packages\\PyCall\\1gn3u\\src\\callback.jl:44>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m单线程环境建立，训练，保持\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mJuliaEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVIVEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_episode_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstatics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m     12\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m reward_callback \u001b[38;5;241m=\u001b[39m RewardLoggerCallback()\n",
      "File \u001b[1;32md:\\python3.1.0\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:31\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[1;34m(self, env_fns)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(fn()) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m         )\n",
      "File \u001b[1;32md:\\python3.1.0\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m单线程环境建立，训练，保持\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mJuliaEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVIVEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_episode_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstatics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m])\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m     12\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m reward_callback \u001b[38;5;241m=\u001b[39m RewardLoggerCallback()\n",
      "File \u001b[1;32me:\\New_Env\\src\\VIV_gym.py:86\u001b[0m, in \u001b[0;36mJuliaEnv.__init__\u001b[1;34m(self, render_mode, env, max_episode_steps, statics, variables, spaces, verbose)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, env \u001b[38;5;241m=\u001b[39m VIVEnv, max_episode_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m     84\u001b[0m              statics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, spaces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# === Julia  ===\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwf \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mgetActionSpace(num \u001b[38;5;241m=\u001b[39m spaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m])                          \u001b[38;5;66;03m# action space\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mgetObservationSpace(num \u001b[38;5;241m=\u001b[39m spaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m])           \u001b[38;5;66;03m# observation space  \u001b[39;00m\n",
      "File \u001b[1;32me:\\New_Env\\src\\VIV_gym.py:34\u001b[0m, in \u001b[0;36mVIVEnv.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32me:\\New_Env\\src\\VIV_gym.py:39\u001b[0m, in \u001b[0;36mVIVEnv.getEnv\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetEnv\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m     38\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIV_Env_3.jl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mMain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Main\u001b[38;5;241m.\u001b[39mVIVEnv\n",
      "\u001b[1;31mSystemError\u001b[0m: <PyCall.jlwrap (in a Julia function called from Python)\nJULIA: SystemError: opening file \"e:\\\\New_Env\\\\src\\\\VIV_Env_3.jl\": No such file or directory\nStacktrace:\n  [1] systemerror(p::String, errno::Int32; extrainfo::Nothing)\n    @ Base .\\error.jl:176\n  [2] systemerror\n    @ .\\error.jl:175 [inlined]\n  [3] open(fname::String; lock::Bool, read::Nothing, write::Nothing, create::Nothing, truncate::Nothing, append::Nothing)\n    @ Base .\\iostream.jl:293\n  [4] open\n    @ .\\iostream.jl:275 [inlined]\n  [5] open(f::Base.var\"#433#434\"{String}, args::String; kwargs::@Kwargs{})\n    @ Base .\\io.jl:394\n  [6] open\n    @ .\\io.jl:393 [inlined]\n  [7] read\n    @ .\\io.jl:486 [inlined]\n  [8] _include(mapexpr::Function, mod::Module, _path::String)\n    @ Base .\\loading.jl:2202\n  [9] include(fname::String)\n    @ Base.MainInclude .\\client.jl:494\n [10] invokelatest(::Any, ::Any, ::Vararg{Any}; kwargs::@Kwargs{})\n    @ Base .\\essentials.jl:892\n [11] invokelatest(::Any, ::Any, ::Vararg{Any})\n    @ Base .\\essentials.jl:889\n [12] _pyjlwrap_call(f::Function, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n    @ PyCall C:\\Users\\admin\\.julia\\packages\\PyCall\\1gn3u\\src\\callback.jl:28\n [13] pyjlwrap_call(self_::Ptr{PyCall.PyObject_struct}, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n    @ PyCall C:\\Users\\admin\\.julia\\packages\\PyCall\\1gn3u\\src\\callback.jl:44>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "单线程环境建立，训练，保持\n",
    "\n",
    "\"\"\"\n",
    "env = DummyVecEnv([lambda: JuliaEnv(render_mode=None, env = VIVEnv, max_episode_steps=2000, statics = statics, \n",
    "                                    variables = variables, spaces = spaces, verbose=1)])\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    device = 'cpu'\n",
    ")\n",
    "reward_callback = RewardLoggerCallback()\n",
    "callback = CallbackList([checkpoint_callback, reward_callback])\n",
    "model.learn(total_timesteps=100_000, callback = callback)\n",
    "model.save(\"PPO_model\")\n",
    "rewards = np.array(reward_callback.episode_rewards)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a89abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "单线程环境建立，训练，保持(注册表)\n",
    "\n",
    "\"\"\"\n",
    "env = DummyVecEnv([lambda: gym.make(\"VIV-v0\")])\n",
    "\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    device = 'cpu'\n",
    ")\n",
    "reward_callback = RewardLoggerCallback()\n",
    "callback = CallbackList([checkpoint_callback, reward_callback])\n",
    "model.learn(total_timesteps=2_000, callback = callback)\n",
    "model.save(\"PPO_model\")\n",
    "rewards = np.array(reward_callback.episode_rewards)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "多线程环境建立\n",
    "\n",
    "\"\"\"\n",
    "def make_env(rank: int, seed: int = 0):\n",
    "    def _init():\n",
    "        env = JuliaVIVEnv(render_mode=None, max_episode_steps=200, verbose=1)\n",
    "        env.reset(seed=seed+rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "num_envs = 4\n",
    "env = SubprocVecEnv([make_env(i) for i in range(num_envs)])\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    device = 'cpu'\n",
    ")\n",
    "reward_callback = RewardLoggerCallback()\n",
    "callback = CallbackList([checkpoint_callback, reward_callback])\n",
    "\n",
    "model.learn(total_timesteps=20_000, callback = callback)\n",
    "model.save(\"ppo_model\")\n",
    "rewards = np.array(reward_callback.episode_rewards)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf25679942131",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(reward_callback.episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e00a8abd73c2c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\python3.1.0\\lib\\multiprocessing\\connection.py:305\u001b[0m, in \u001b[0;36mPipeConnection._recv_bytes\u001b[1;34m(self, maxsize)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING:\n\u001b[1;32m--> 305\u001b[0m     waitres \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINFINITE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m waitres \u001b[38;5;241m==\u001b[39m WAIT_OBJECT_0\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\python3.1.0\\lib\\multiprocessing\\connection.py:312\u001b[0m, in \u001b[0;36mPipeConnection._recv_bytes\u001b[1;34m(self, maxsize)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     nread, err \u001b[38;5;241m=\u001b[39m \u001b[43mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetOverlappedResult\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [WinError 109] 管道已结束。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _init\n\u001b[0;32m     14\u001b[0m num_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m---> 15\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mSubprocVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m reward_callback \u001b[38;5;241m=\u001b[39m RewardLoggerCallback()\n\u001b[0;32m     18\u001b[0m callback \u001b[38;5;241m=\u001b[39m CallbackList([checkpoint_callback, reward_callback])\n",
      "File \u001b[1;32md:\\python3.1.0\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\subproc_vec_env.py:127\u001b[0m, in \u001b[0;36mSubprocVecEnv.__init__\u001b[1;34m(self, env_fns, start_method)\u001b[0m\n\u001b[0;32m    124\u001b[0m     work_remote\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremotes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_spaces\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 127\u001b[0m observation_space, action_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremotes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mlen\u001b[39m(env_fns), observation_space, action_space)\n",
      "File \u001b[1;32md:\\python3.1.0\\lib\\multiprocessing\\connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[1;32md:\\python3.1.0\\lib\\multiprocessing\\connection.py:321\u001b[0m, in \u001b[0;36mPipeConnection._recv_bytes\u001b[1;34m(self, maxsize)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwinerror \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mERROR_BROKEN_PIPE:\n\u001b[1;32m--> 321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "加载checkpoint并继续训练\n",
    "\n",
    "\"\"\"\n",
    "def make_env(rank: int, seed: int = 0):\n",
    "    def _init():\n",
    "        env = JuliaDragEnv(render_mode=None, max_episode_steps=30, verbose=1)\n",
    "        env.reset(seed=seed+rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "num_envs = 4\n",
    "env = SubprocVecEnv([make_env(i) for i in range(num_envs)])\n",
    "\n",
    "reward_callback = RewardLoggerCallback()\n",
    "callback = CallbackList([checkpoint_callback, reward_callback])\n",
    "\n",
    "model = PPO.load(\"./checkpoints/ppo_model_40000_steps\", env=env, device='cpu')\n",
    "model.learn(total_timesteps=20_000, callback = callback)\n",
    "rewards_ex = np.array(reward_callback.episode_rewards)\n",
    "rewards = [rewards, rewards_ex]\n",
    "model.save(\"./model_stage/ppo_model_40k\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f930ccd7507654ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T03:35:29.970382Z",
     "start_time": "2025-08-11T03:35:23.541861Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "绘图功能\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 参数：滑动窗口大小\n",
    "window = 10\n",
    "\n",
    "def plot_rewards(rewards, window=100):\n",
    "    episode = np.arange(len(rewards))\n",
    "\n",
    "    # 计算滑动均值和标准差\n",
    "    def moving_avg(x, w):\n",
    "        return np.convolve(x, np.ones(w)/w, mode='valid')\n",
    "\n",
    "    mean = moving_avg(rewards, window)\n",
    "    std = np.array([\n",
    "        np.std(rewards[max(0, i - window + 1):i + 1])\n",
    "        for i in range(window - 1, len(rewards))\n",
    "    ])\n",
    "\n",
    "    # 对应 x 轴\n",
    "    x = np.arange(window - 1, len(rewards))\n",
    "\n",
    "    # 绘图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(x, mean, label='Mean Reward')\n",
    "    plt.fill_between(x, mean - std, mean + std, alpha=0.3, label='±1 Std Dev')\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Episode Reward over Training\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_rewards(rewards,window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8e6b296ccfe1a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-08-11T03:35:38.095121Z"
    }
   },
   "outputs": [],
   "source": [
    "#训练结束后出gif\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import SAC\n",
    "from model.VIV_gym import JuliaEnv\n",
    "from gif import create_GIF\n",
    "\n",
    "infos = []\n",
    "\n",
    "# 创建开启渲染的环境\n",
    "env = JuliaEnv(render_mode=\"rgb_array\", env = VIVEnv, max_episode_steps=2000, statics = statics, variables = variables, spaces = spaces, verbose=True)\n",
    "\n",
    "# 加载训练好的模型\n",
    "model = SAC.load(\"SAC_model\", env=env)\n",
    "\n",
    "# 视频帧列表\n",
    "frames = []\n",
    "\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "while not done and not truncated:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "# 保存为GIF（也可以保存为MP4）\n",
    "input_frame = \"images\"\n",
    "output_gif = \"train_policy_demo.gif\"\n",
    "create_GIF(input_frame, output_gif)\n",
    "env.close()\n",
    "\n",
    "np.save(\"info_SAC.npy\", info[\"info\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5881cc034ba9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T10:03:18.150239Z",
     "start_time": "2025-08-06T10:03:17.033327Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "info = np.load(\"info_SAC.npy\", allow_pickle=True)\n",
    "# force = info\n",
    "force = [f[\"F\"] for f in info[0:]]\n",
    "y_force = [f[\"fluid_force_y\"] for f in info[0:]]\n",
    "x_force = [f[\"fluid_force_x\"] for f in info[0:]]\n",
    "y_dis = [f[\"y_dis\"] for f in info[0:]]\n",
    "x_dis = [f[\"x_dis\"] for f in info[0:]]\n",
    "\n",
    "# info2 = np.load(\"info2_SAC.npy\", allow_pickle=True)\n",
    "# y_dis2 = [f[\"y_dis\"] for f in info2[0:]]\n",
    "\n",
    "\n",
    "x = np.arange(len(y_force))\n",
    "# x2 = np.arange(len(y_dis2))\n",
    "\n",
    "# 画图\n",
    "plt.figure(figsize=(8, 5))\n",
    "# plt.plot(x, force, label=\"ratio\", color=\"red\")\n",
    "plt.plot(x, force, label=\"x_force\", color=\"red\")\n",
    "plt.plot(x, x_force, label=\"x_fluid\", color=\"blue\")\n",
    "plt.plot(x, x_dis, label=\"x_displacement\", color=\"green\")\n",
    "# plt.plot(x2, y_dis2, label=\"init_displacement\", color=\"yellow\")\n",
    "\n",
    "# 图例、标签、标题\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"force & displacement\")\n",
    "plt.title(\"Force and Displacement in x direction\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99718faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gif import create_GIF\n",
    "# 保存为GIF（也可以保存为MP4）\n",
    "input_frame = \"images\"\n",
    "output_gif = \"train_policy_demo.gif\"\n",
    "create_GIF(input_frame, output_gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a3a4c72317778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx_no = np.load(\"none_train.npy\")\n",
    "nx_tr = np.load(\"train.npy\")\n",
    "y_cons = np.load(\"x_cons.npy\")\n",
    "\n",
    "x = np.arange(len(nx_no))\n",
    "\n",
    "# 画图\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y_cons, label=\"Y_Constrained\", color=\"yellow\")\n",
    "plt.plot(x, nx_no, label=\"Init_VIV\", color=\"blue\")\n",
    "plt.plot(x, nx_tr, label=\"SAC_Trained\", color=\"red\")\n",
    "\n",
    "# 图例、标签、标题\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"X - Value\")\n",
    "plt.title(\"Comparison of Displacement in X-Direction\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd743b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VIV_gym import VIVEnv\n",
    "# ===== Register to Gym =====\n",
    "gym.register(\n",
    "    id=\"VIV-v0\",\n",
    "    entry_point=JuliaEnv,\n",
    "    kwargs={\n",
    "        \"env\": VIVEnv,\n",
    "        \"statics\": {\"L_unit\": 16, \"F_scale\": 1.0, \"size\": (10, 8), \"location\": [3, 4]},  # 这里要替换成你实际的参数\n",
    "        \"variables\": {\"position\":[0.0, -1.0], \"velocity\":[0.0, 0.0]},\n",
    "        \"spaces\": {\"action\": 1, \"observation\": 3},\n",
    "        \"verbose\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14367287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"VIV-v0\")\n",
    "obs, info = env.reset()\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
